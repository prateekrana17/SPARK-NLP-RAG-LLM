{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPivv//O1LttWWm6ivMzhCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekrana17/SPARK-NLP-RAG-LLM/blob/main/SPARK-NLP-latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxlZ_XaNMVch",
        "outputId": "8f39e5f4-de43-4898-870e-aa7f8f60400f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-15 06:17:02--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘colab_setup.sh’\n",
            "\n",
            "\rcolab_setup.sh        0%[                    ]       0  --.-KB/s               \rcolab_setup.sh      100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-15 06:17:02 (37.9 MB/s) - ‘colab_setup.sh’ saved [1191/1191]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash colab_setup.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bszxMJupMXVT",
        "outputId": "d8714123-52fb-4db8-bb1a-5e853fda71b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PySpark 3.2.3 and Spark NLP 5.3.3\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "metadata": {
        "id": "0El7iR1SlN3F",
        "outputId": "f22e5773-55eb-40ac-c968-5b0451f5247b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c9df693f6a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://556f9ce42952:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sparknlp\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from pyspark.sql.types import StringType, IntegerType"
      ],
      "metadata": {
        "id": "UoOE_p5SMW7x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detection model_name = 'ld_wiki_cnn_231'\n",
        "model_name = 'ld_wiki_tatoeba_cnn_375'"
      ],
      "metadata": {
        "id": "7LiDrLq_MW4n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Die Mona Lisa ist ein von Leonardo geschaffenes Ölgemälde aus dem 16. Jahrhundert. Sie findet im Louvre in Paris statt.\"\"\"  #document/ ECM retireved text\n",
        "\n",
        "text2 = \"\"\"Ich liebe Datenwissenschaf\"\"\""
      ],
      "metadata": {
        "id": "BXlMYk7gJSs1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create spark data frame\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "    [text],\n",
        "    [text2]]).toDF(\"text\")"
      ],
      "metadata": {
        "id": "WmihrZzpJWde"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detection pipeline for 100+ languages\n",
        "\n",
        "# Step 1: Transforms raw texts to `document` annotation\n",
        "document_assembler = (\n",
        "    DocumentAssembler()\n",
        "    .setInputCol(\"text\")\n",
        "    .setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "            .setInputCol(\"text\")\\\n",
        "            .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "            .setInputCols([\"document\"]) \\\n",
        "            .setOutputCol(\"sentence\")\n",
        "\n",
        "# Step 2: Determines the language of the text\n",
        "languageDetector = LanguageDetectorDL.pretrained(model_name)\\\n",
        "            .setInputCols(\"sentence\")\\\n",
        "            .setOutputCol(\"language\")\\\n",
        "            .setThreshold(0.5)\\\n",
        "            .setCoalesceSentences(True)\n",
        "\n",
        "nlpPipeline = Pipeline(\n",
        "    stages=[\n",
        "        documentAssembler,\n",
        "        sentence_detector,\n",
        "        languageDetector])\n"
      ],
      "metadata": {
        "id": "MW6ZIZK8mFQC",
        "outputId": "e9f04443-1cd2-4b8a-d845-4d4585102243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ld_wiki_tatoeba_cnn_375 download started this may take some time.\n",
            "Approximate size to download 8.8 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#language detection\n",
        "result = nlpPipeline.fit(data).transform(data)\n",
        "result.select(\"text\", \"language.result\").show()"
      ],
      "metadata": {
        "id": "da6mS_jBHtZo",
        "outputId": "03b23207-0f68-4bf2-8c1d-21676e33b814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|                text|result|\n",
            "+--------------------+------+\n",
            "|Die Mona Lisa ist...|  [de]|\n",
            "|Ich liebe Datenwi...|  [de]|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tranlsation\n",
        "t_list= []"
      ],
      "metadata": {
        "id": "t4U-HETPIdRx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation pipeline\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "## More accurate Sentence Detection using Deep Learning\n",
        "sentencerDL = SentenceDetectorDLModel()\\\n",
        "  .pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentences\")\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_it_en\", \"xx\")\\\n",
        "  .setInputCols([\"sentences\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[\n",
        "        documentAssembler,\n",
        "        sentencerDL,\n",
        "        marian\n",
        "        ])"
      ],
      "metadata": {
        "id": "T5SrBy3EIGuu",
        "outputId": "0fc60488-fbd1-4c46-cbdb-5dcb9f82d3de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_it_en download started this may take some time.\n",
            "Approximate size to download 454.8 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-YiQs9LRIFv4",
        "outputId": "ce23d531-8136-411f-babe-71627a51fd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "requirement failed: Wrong or missing inputCols annotators in LANGUAGE_DETECTOR_DL_b307513d73d0.\n\nCurrent inputCols: sentence. Dataset's columns:\n(column_name=text,is_nlp_annotator=false)\n(column_name=document,is_nlp_annotator=true,type=document).\nMake sure such annotators exist in your pipeline, with the right output names and that they have following annotator types: document",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5654b13115bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlpPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"language.result\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Wrong or missing inputCols annotators in LANGUAGE_DETECTOR_DL_b307513d73d0.\n\nCurrent inputCols: sentence. Dataset's columns:\n(column_name=text,is_nlp_annotator=false)\n(column_name=document,is_nlp_annotator=true,type=document).\nMake sure such annotators exist in your pipeline, with the right output names and that they have following annotator types: document"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create spark Data Frame for displaying detection results\n",
        "df = spark.createDataFrame(user_text, StringType()).toDF(\"text\")\n",
        "result = nlpPipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "04fFqTanmFMT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tranlation pipeline\n",
        "\n",
        "\n",
        "## More accurate Sentence Detection using Deep Learning\n",
        "sentencerDL = SentenceDetectorDLModel()\\\n",
        "  .pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentences\")\n",
        "\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_it_en\", \"xx\")\\\n",
        "  .setInputCols([\"sentences\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "nlp_pipeline2 = Pipeline(\n",
        "    stages=[\n",
        "        documentAssembler,\n",
        "        sentencerDL,\n",
        "        marian\n",
        "        ])"
      ],
      "metadata": {
        "id": "m7UInfeh8FdH",
        "outputId": "d261e2d4-7b2a-4eaf-e89d-9fd7ffc09a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_it_en download started this may take some time.\n",
            "Approximate size to download 454.8 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translation dataframe\n",
        "\n",
        "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
        "pipeline_model = nlp_pipeline2.fit(empty_df)\n",
        "lmodel = LightPipeline(pipeline_model)\n",
        "res = lmodel.fullAnnotate(translation_text)\n"
      ],
      "metadata": {
        "id": "ZvsYRe0p9d8O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1naHVA49dyZ",
        "outputId": "3fc59bc7-02d1-435d-8dec-8a7b9c21aed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'document': [Annotation(document, 0, 4338, Mona Lisa is a 16th century oil painting created by Leonardo. It is held at the Louvre in Paris. La Joconde est une peinture à l'huile du XVIe siècle créée par Léonard. Il se tient au Louvre à Paris. Джефри Еверест Хинтън е британски канадски когнитивен психолог и компютърен учен, най-известен с работата си върху изкуствени невронни мрежи. От 2013 г. той прекарва времето си в работа за Google и университета в Торонто. През 2017 г. е съосновател и става главен научен съветник на Vector Institute of Toronto. Mona Lisa je olejomalba ze 16. století, kterou vytvořil Leonardo. Koná se v Louvru v Paříži. Titanic ist ein 1997 in den USA veröffentlichter epischer Roman und ein katastrophaler Film, der von James Cameron inszeniert, geschrieben, co-produziert und mitherausgegeben wurde. Es deckt sowohl historische als auch fiktive Aspekte ab und basiert auf Berichten über den Untergang der RMS Titanic und der Stars Leonard DiCaprio und Kate Winslet als Mitglieder verschiedener sozialer Klassen, die sich während der Schiffsreise während ihrer unglücklichen ersten Reise verlieben. Το Titanic είναι ένα αμερικανικό επικό μυθιστόρημα του 1997 και μια καταστροφική ταινία σε σκηνοθεσία, συγγραφή, συμπαραγωγή και συν-επεξεργασία από τον James Cameron. Καλύπτει τόσο ιστορικές όσο και φανταστικές πτυχές και βασίζεται σε αναφορές για τη βύθιση του Τιτανικού RMS και πρωταγωνιστούν οι Leonard DiCaprio και Kate Winslet ως μέλη διαφόρων κοινωνικών τάξεων που ερωτεύονται κατά τη διάρκεια του ταξιδιού του πλοίου κατά τη διάρκεια του πρώτου τους ατυχούς ταξιδιού. Geoffrey Everest Hinton es un psicólogo cognitivo y científico informático británico canadiense, mejor conocido por su trabajo en redes neuronales artificiales. Desde 2013 ha pasado su tiempo trabajando para Google y la Universidad de Toronto. En 2017 fue cofundador y se convirtió en Asesor Científico Jefe del Instituto Vector de Toronto. Mona Lisa on 1500-luvun öljymaalaus, jonka on luonut Leonardo. Se pidetään Pariisin Louvressa. A természetes nyelvfeldolgozás története általában az 1950-es években kezdődött, bár a korábbi időszakokból származó munkák is megtalálhatók. 1950-ben Alan Turing közzétett egy cikket, melynek címe: „Számítástechnika és intelligenciagépek”, és amely intelligenciakritériumként javasolta a Turing-tesztet. Titanic er en amerikansk episk roman fra 1997 og katastrofal film regissert, skrevet, co-produsert og co-redigert av James Cameron. Det dekker både historiske og fiksjoniserte aspekter og er basert på rapporter om synkingen av RMS Titanic og stjernene Leonard DiCaprio og Kate Winslet som medlemmer av forskjellige sosiale klasser som forelsker seg under skipets seilas under deres uheldige første seilas. Poza tym, że jest królem północy, John Snow jest angielskim lekarzem i liderem w dziedzinie anestezjologii i higieny medycznej. Uważany jest za pierwszego, który wykorzystał dane do leczenia epidemii cholery w 1834 r. Geoffrey Everest Hinton é um psicólogo cognitivo britânico canadense e cientista da computação, mais conhecido por seu trabalho em redes neurais artificiais. Desde 2013, ele trabalha para o Google e a Universidade de Toronto. Em 2017, foi co-fundador e tornou-se Conselheiro Científico Chefe do Vector Institute of Toronto. Mona Lisa este o pictură în ulei din secolul al XVI-lea creată de Leonardo. Se ține la Louvre din Paris. Когда в 2007 году Себастьян Трун начал работать над машинами для самостоятельного вождения в Google, мало кто за пределами компании воспринимал его всерьез. John Snow je okrem anglického kráľa anglickým lekárom a lídrom vo vývoji anestézie a lekárskej hygieny. Je považovaný za prvého, ktorý používa údaje na liečenie prepuknutia cholery v roku 1834. Mona Lisa är en oljemålning från 1500-talet skapad av Leonardo. Det hålls vid Louvre i Paris. Mona Lisa, Leonardo tarafından yaratılan 16. yüzyıldan kalma bir yağlı boyadır. Paris'teki Louvre'da düzenleniyor. Facebook - це послуга соціальних мереж, запущена під назвою TheFacebook 4 лютого 2004 року. Його заснував Марк Цукерберг разом зі своїми одноквартами та колегами Гарвардського університету Едуардо Саверином, Ендрю Макколлумом, Дастіном Московіцем та Крісом Х'юзом. Quando Sebastian Thrun ha iniziato a lavorare su auto a guida autonoma presso Google nel 2007, poche persone al di fuori dell'azienda lo hanno preso sul serio., {}, [])], 'sentences': [Annotation(document, 0, 60, Mona Lisa is a 16th century oil painting created by Leonardo., {'sentence': '0'}, []), Annotation(document, 62, 95, It is held at the Louvre in Paris., {'sentence': '1'}, []), Annotation(document, 97, 167, La Joconde est une peinture à l'huile du XVIe siècle créée par Léonard., {'sentence': '2'}, []), Annotation(document, 169, 198, Il se tient au Louvre à Paris., {'sentence': '3'}, []), Annotation(document, 200, 340, Джефри Еверест Хинтън е британски канадски когнитивен психолог и компютърен учен, най-известен с работата си върху изкуствени невронни мрежи., {'sentence': '4'}, []), Annotation(document, 342, 420, От 2013 г. той прекарва времето си в работа за Google и университета в Торонто., {'sentence': '5'}, []), Annotation(document, 422, 510, През 2017 г. е съосновател и става главен научен съветник на Vector Institute of Toronto., {'sentence': '6'}, []), Annotation(document, 512, 576, Mona Lisa je olejomalba ze 16. století, kterou vytvořil Leonardo., {'sentence': '7'}, []), Annotation(document, 578, 603, Koná se v Louvru v Paříži., {'sentence': '8'}, []), Annotation(document, 605, 785, Titanic ist ein 1997 in den USA veröffentlichter epischer Roman und ein katastrophaler Film, der von James Cameron inszeniert, geschrieben, co-produziert und mitherausgegeben wurde., {'sentence': '9'}, []), Annotation(document, 787, 1083, Es deckt sowohl historische als auch fiktive Aspekte ab und basiert auf Berichten über den Untergang der RMS Titanic und der Stars Leonard DiCaprio und Kate Winslet als Mitglieder verschiedener sozialer Klassen, die sich während der Schiffsreise während ihrer unglücklichen ersten Reise verlieben., {'sentence': '10'}, []), Annotation(document, 1085, 1251, Το Titanic είναι ένα αμερικανικό επικό μυθιστόρημα του 1997 και μια καταστροφική ταινία σε σκηνοθεσία, συγγραφή, συμπαραγωγή και συν-επεξεργασία από τον James Cameron., {'sentence': '11'}, []), Annotation(document, 1253, 1559, Καλύπτει τόσο ιστορικές όσο και φανταστικές πτυχές και βασίζεται σε αναφορές για τη βύθιση του Τιτανικού RMS και πρωταγωνιστούν οι Leonard DiCaprio και Kate Winslet ως μέλη διαφόρων κοινωνικών τάξεων που ερωτεύονται κατά τη διάρκεια του ταξιδιού του πλοίου κατά τη διάρκεια του πρώτου τους ατυχούς ταξιδιού., {'sentence': '12'}, []), Annotation(document, 1561, 1720, Geoffrey Everest Hinton es un psicólogo cognitivo y científico informático británico canadiense, mejor conocido por su trabajo en redes neuronales artificiales., {'sentence': '13'}, []), Annotation(document, 1722, 1803, Desde 2013 ha pasado su tiempo trabajando para Google y la Universidad de Toronto., {'sentence': '14'}, []), Annotation(document, 1805, 1900, En 2017 fue cofundador y se convirtió en Asesor Científico Jefe del Instituto Vector de Toronto., {'sentence': '15'}, []), Annotation(document, 1902, 1963, Mona Lisa on 1500-luvun öljymaalaus, jonka on luonut Leonardo., {'sentence': '16'}, []), Annotation(document, 1965, 1995, Se pidetään Pariisin Louvressa., {'sentence': '17'}, []), Annotation(document, 1997, 2137, A természetes nyelvfeldolgozás története általában az 1950-es években kezdődött, bár a korábbi időszakokból származó munkák is megtalálhatók., {'sentence': '18'}, []), Annotation(document, 2139, 2300, 1950-ben Alan Turing közzétett egy cikket, melynek címe: „Számítástechnika és intelligenciagépek”, és amely intelligenciakritériumként javasolta a Turing-tesztet., {'sentence': '19'}, []), Annotation(document, 2302, 2432, Titanic er en amerikansk episk roman fra 1997 og katastrofal film regissert, skrevet, co-produsert og co-redigert av James Cameron., {'sentence': '20'}, []), Annotation(document, 2434, 2706, Det dekker både historiske og fiksjoniserte aspekter og er basert på rapporter om synkingen av RMS Titanic og stjernene Leonard DiCaprio og Kate Winslet som medlemmer av forskjellige sosiale klasser som forelsker seg under skipets seilas under deres uheldige første seilas., {'sentence': '21'}, []), Annotation(document, 2708, 2834, Poza tym, że jest królem północy, John Snow jest angielskim lekarzem i liderem w dziedzinie anestezjologii i higieny medycznej., {'sentence': '22'}, []), Annotation(document, 2836, 2924, Uważany jest za pierwszego, który wykorzystał dane do leczenia epidemii cholery w 1834 r., {'sentence': '23'}, []), Annotation(document, 2926, 3082, Geoffrey Everest Hinton é um psicólogo cognitivo britânico canadense e cientista da computação, mais conhecido por seu trabalho em redes neurais artificiais., {'sentence': '24'}, []), Annotation(document, 3084, 3150, Desde 2013, ele trabalha para o Google e a Universidade de Toronto., {'sentence': '25'}, []), Annotation(document, 3152, 3248, Em 2017, foi co-fundador e tornou-se Conselheiro Científico Chefe do Vector Institute of Toronto., {'sentence': '26'}, []), Annotation(document, 3250, 3324, Mona Lisa este o pictură în ulei din secolul al XVI-lea creată de Leonardo., {'sentence': '27'}, []), Annotation(document, 3326, 3353, Se ține la Louvre din Paris., {'sentence': '28'}, []), Annotation(document, 3355, 3510, Когда в 2007 году Себастьян Трун начал работать над машинами для самостоятельного вождения в Google, мало кто за пределами компании воспринимал его всерьез., {'sentence': '29'}, []), Annotation(document, 3512, 3614, John Snow je okrem anglického kráľa anglickým lekárom a lídrom vo vývoji anestézie a lekárskej hygieny., {'sentence': '30'}, []), Annotation(document, 3616, 3704, Je považovaný za prvého, ktorý používa údaje na liečenie prepuknutia cholery v roku 1834., {'sentence': '31'}, []), Annotation(document, 3706, 3768, Mona Lisa är en oljemålning från 1500-talet skapad av Leonardo., {'sentence': '32'}, []), Annotation(document, 3770, 3798, Det hålls vid Louvre i Paris., {'sentence': '33'}, []), Annotation(document, 3800, 3878, Mona Lisa, Leonardo tarafından yaratılan 16. yüzyıldan kalma bir yağlı boyadır., {'sentence': '34'}, []), Annotation(document, 3880, 3913, Paris'teki Louvre'da düzenleniyor., {'sentence': '35'}, []), Annotation(document, 3915, 4005, Facebook - це послуга соціальних мереж, запущена під назвою TheFacebook 4 лютого 2004 року., {'sentence': '36'}, []), Annotation(document, 4007, 4178, Його заснував Марк Цукерберг разом зі своїми одноквартами та колегами Гарвардського університету Едуардо Саверином, Ендрю Макколлумом, Дастіном Московіцем та Крісом Х'юзом., {'sentence': '37'}, []), Annotation(document, 4180, 4338, Quando Sebastian Thrun ha iniziato a lavorare su auto a guida autonoma presso Google nel 2007, poche persone al di fuori dell'azienda lo hanno preso sul serio., {'sentence': '38'}, [])], 'translation': [Annotation(document, 0, 60, Mona Lisa is a 16th century oil painting created by Leonardo., {'sentence': '0'}, []), Annotation(document, 61, 93, It is held at the Louvre in Paris., {'sentence': '1'}, []), Annotation(document, 155, 162, La Joconde est une peinture à l'huile du XVIe siècle crée par Léonard., {'sentence': '2'}, []), Annotation(document, 318, 192, The se tient au Louvre à Paris., {'sentence': '3'}, []), Annotation(document, 511, 234, Джефри Еверест итън е британски канадски ко, {'sentence': '4'}, []), Annotation(document, 746, 287, От 2013 г. тойтоекарва времето си в работат и Google и, {'sentence': '5'}, []), Annotation(document, 1034, 338, През 2017 г. е съосновател и става главен научен съв, {'sentence': '6'}, []), Annotation(document, 1373, 402, Mona Lisa je olejomalba ze 16. století, kterou vytvořil Leonardo., {'sentence': '7'}, []), Annotation(document, 1776, 427, Koná se v Louvru v Paříži., {'sentence': '8'}, []), Annotation(document, 2204, 535, Titanic ist ein 1997 in den USA veröffentlichter epischer Roman und ein katastrophaler Film, der von James Ca, {'sentence': '9'}, []), Annotation(document, 2740, 633, Es deckt sowohl historische als auch fiktive Aspekte ab und basiert auf Brichten über den Untergang, {'sentence': '10'}, []), Annotation(document, 3374, 683, Το Titanic ριναι ένα αμερικανικό επικό μυθιτόρημα τ, {'sentence': '11'}, []), Annotation(document, 4058, 724, Καλύπτττόσο ίτορικές όσο και φαντατικές πτ, {'sentence': '12'}, []), Annotation(document, 4783, 824, Geoffrey Everest Hinton es un psicólogo cognitiveo y científico informático británico canadiense, mej, {'sentence': '13'}, []), Annotation(document, 5608, 906, Desde 2013 has pasado on tiempo trabajando para Google y la Universidad de Toronto., {'sentence': '14'}, []), Annotation(document, 6515, 1001, In 2017 fue cofundador y se convirtió en Asesor Científico Jefe del Instituto Vector de Toronto., {'sentence': '15'}, []), Annotation(document, 7517, 1062, Mona Lisa on 1500-luvun öljymaalaus, jonka on luonut Leonardo., {'sentence': '16'}, []), Annotation(document, 8580, 1092, Se pidetään Pariisin Louvressa., {'sentence': '17'}, []), Annotation(document, 9673, 1167, A természetes Nyelvfeldolgozás története általában az 1950-es években kezdőd, {'sentence': '18'}, []), Annotation(document, 10841, 1242, 1950-ben Alan Turing közzétett egy cikket, melynek címe: \" Számítástechnika , {'sentence': '19'}, []), Annotation(document, 12084, 1341, Titanic er en amerikansk episk roman fra 1997 og katastrofal film regissert, skrevet, co-produsert o, {'sentence': '20'}, []), Annotation(document, 13426, 1425, Det dekker både historiske og fiksjoniserte aspekter og er basert på rapporter om syn, {'sentence': '21'}, []), Annotation(document, 14852, 1501, Poza tym, że jest królem łonocy, John Snow jest angielskim lekarzem i liderem, {'sentence': '22'}, []), Annotation(document, 16354, 1582, Uważany jest za pierwszego, który wykorzystał dane do lcenia epidemii cholery w 18, {'sentence': '23'}, []), Annotation(document, 17937, 1687, Geoffrey Everest Hinton is a cognitive psicólogo britânico canadense e cientista da computação, mais conhe, {'sentence': '24'}, []), Annotation(document, 19625, 1753, Desde 2013, ele trabalha para o Google e a Universidade de Toronto., {'sentence': '25'}, []), Annotation(document, 21379, 1849, Em 2017, foi co-fundador e tornou-se Conselheiro Científico Chefe do Vector Institute of Toronto., {'sentence': '26'}, []), Annotation(document, 23229, 1923, Mona Lisa este o pictură în ulei din secolul al XVI-lea creată de Leonardo., {'sentence': '27'}, []), Annotation(document, 25153, 1949, Ifține la Louvre din Paris., {'sentence': '28'}, []), Annotation(document, 27103, 1996, Когда в 2007 годуСебастьян Трун начал работть на, {'sentence': '29'}, []), Annotation(document, 29100, 2072, John Snow je okrem anglického kráľa anglickým likárom a lídrom vo vývoji anes, {'sentence': '30'}, []), Annotation(document, 31173, 2145, Je považovaný za prvého, ktorý používa údaje na liečenie prepuknutia chole, {'sentence': '31'}, []), Annotation(document, 33319, 2207, Mona Lisa är en oljemålning från 1500-talet skapad av Leonardo., {'sentence': '32'}, []), Annotation(document, 35527, 2235, Det hålls vid Louvre i Paris., {'sentence': '33'}, []), Annotation(document, 37763, 2312, Mona Lisa, Leonardo tarafından yaratılan 16. yüzyıldan kalma bir yağlı boyadır, {'sentence': '34'}, []), Annotation(document, 40076, 2345, Paris'teki Louvre'da düzenleniyor., {'sentence': '35'}, []), Annotation(document, 42422, 2394, Facebook - це послуга социальних мереж, пуена пена, {'sentence': '36'}, []), Annotation(document, 44817, 2393, , {'sentence': '37'}, []), Annotation(document, 47211, 2523, When Sebastian Thrun started working on autonomous car driving at Google in 2007, few people outside the company took it seriously., {'sentence': '38'}, [])]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V06KFs179dtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzC32WLG9dq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HG8ezZRY9dnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4SxQTXx8FY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riLxZTTj7s30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}