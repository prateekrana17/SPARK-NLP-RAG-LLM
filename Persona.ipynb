{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeZ+0CKtDK4etxJ9ELPiyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekrana17/SPARK-NLP-RAG-LLM/blob/main/Persona.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bmmd2HcHfov",
        "outputId": "b112f618-1478-4c75-a415-314d4d710d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-03 10:23:06--  https://github.com/prateekrana17-offi/awesome-python-applications/blob/master/text_data_amit.txt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘text_data_amit.txt’\n",
            "\n",
            "\rtext_data_amit.txt      [<=>                 ]       0  --.-KB/s               \rtext_data_amit.txt      [ <=>                ] 166.37K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-07-03 10:23:07 (15.5 MB/s) - ‘text_data_amit.txt’ saved [170365]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/prateekrana17-offi/awesome-python-applications/blob/master/text_data_amit.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/prateekrana17-offi/awesome-python-applications/blob/master/text_data_barrie.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulWXvGzHrDN",
        "outputId": "e848c2c1-9197-4f96-a337-b01a1acf40ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-03 10:23:37--  https://github.com/prateekrana17-offi/awesome-python-applications/blob/master/text_data_barrie.txt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘text_data_barrie.txt’\n",
            "\n",
            "text_data_barrie.tx     [ <=>                ] 356.04K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-07-03 10:23:37 (30.3 MB/s) - ‘text_data_barrie.txt’ saved [364584]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY4yMeUJHyVC",
        "outputId": "d463b51f-d46e-44be-804a-6c02bd965a09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Using cached streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.36.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7MLRLNFHyPY",
        "outputId": "d294e3de-96f3-42dd-a923-d14b0930a888"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.81.tar.gz (50.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.81-cp310-cp310-linux_x86_64.whl size=2762350 sha256=17a6d668037e61ff18b9e827123aed020f5cf0c67a5bfe0326c4884bb091a834\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/4a/7f/592e73429da89e4086bbd65cda7197ab53c403c17d386894cd\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvGtdkHnHyMR",
        "outputId": "932385c8-0124-4876-d30f-38d871c1f29e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from llama_cpp import Llama\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "import json\n",
        "import nltk\n",
        "from transformers import BartTokenizer\n",
        "\n",
        "from nltk.tokenize import sent_tokenize  # Import sentence tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX6cioHIHyZT",
        "outputId": "e01bd2da-a7d2-4c75-8ed2-97adc556c3e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/s3nh/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q8_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEHT7Aa8HyHn",
        "outputId": "535ee1c2-57f0-4d98-dd30-d3e8232190f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-03 10:32:45--  https://huggingface.co/s3nh/Kunoichi-DPO-v2-7B-GGUF/resolve/main/kunoichi-dpo-v2-7b.Q8_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.4.7, 18.238.4.30, 18.238.4.28, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.4.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/7a/f0/7af0cac23702d5b24ccb1187e1de40598aec59d3363aa74903487d6204c7e08d/7cfc4ec1a1fb3c022aeaec258571cbb098b8d93fd4389247d993264e274af321?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27kunoichi-dpo-v2-7b.Q8_0.gguf%3B+filename%3D%22kunoichi-dpo-v2-7b.Q8_0.gguf%22%3B&Expires=1720261965&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDI2MTk2NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzdhL2YwLzdhZjBjYWMyMzcwMmQ1YjI0Y2NiMTE4N2UxZGU0MDU5OGFlYzU5ZDMzNjNhYTc0OTAzNDg3ZDYyMDRjN2UwOGQvN2NmYzRlYzFhMWZiM2MwMjJhZWFlYzI1ODU3MWNiYjA5OGI4ZDkzZmQ0Mzg5MjQ3ZDk5MzI2NGUyNzRhZjMyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=YZmzlXZzZuSkQc0kEwXsnKMrf-OFFruqLRRKR%7EhFUZAqxT2WyhS5yPSlvPPFbTk4EKPTd8SHz2j-BJErgHCEduimz6L-g-Zs78fFLfzyv%7Eock2XRpW-JPth2fBvXS36Y6QAyV10W-x9y%7ECNIHfOkISgwwB6p5hQsULqAK1exYSfAYtzSpO2iB8P-hSEULBmCNDHREbf18UJWEzqhTQDVp1PNXXHSRjZWoWGqdAxxh2MTS5q5vcof72bELYlCt-mRvMk49kZ2%7EbdXyOR-VZ0EXjMisEYCF1NiPimkIzum7WGxbaxk4pz2FfSQjCY0zHXgoP0h1dadJe4DCWu25q4MhA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-07-03 10:32:45--  https://cdn-lfs-us-1.huggingface.co/repos/7a/f0/7af0cac23702d5b24ccb1187e1de40598aec59d3363aa74903487d6204c7e08d/7cfc4ec1a1fb3c022aeaec258571cbb098b8d93fd4389247d993264e274af321?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27kunoichi-dpo-v2-7b.Q8_0.gguf%3B+filename%3D%22kunoichi-dpo-v2-7b.Q8_0.gguf%22%3B&Expires=1720261965&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDI2MTk2NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzdhL2YwLzdhZjBjYWMyMzcwMmQ1YjI0Y2NiMTE4N2UxZGU0MDU5OGFlYzU5ZDMzNjNhYTc0OTAzNDg3ZDYyMDRjN2UwOGQvN2NmYzRlYzFhMWZiM2MwMjJhZWFlYzI1ODU3MWNiYjA5OGI4ZDkzZmQ0Mzg5MjQ3ZDk5MzI2NGUyNzRhZjMyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=YZmzlXZzZuSkQc0kEwXsnKMrf-OFFruqLRRKR%7EhFUZAqxT2WyhS5yPSlvPPFbTk4EKPTd8SHz2j-BJErgHCEduimz6L-g-Zs78fFLfzyv%7Eock2XRpW-JPth2fBvXS36Y6QAyV10W-x9y%7ECNIHfOkISgwwB6p5hQsULqAK1exYSfAYtzSpO2iB8P-hSEULBmCNDHREbf18UJWEzqhTQDVp1PNXXHSRjZWoWGqdAxxh2MTS5q5vcof72bELYlCt-mRvMk49kZ2%7EbdXyOR-VZ0EXjMisEYCF1NiPimkIzum7WGxbaxk4pz2FfSQjCY0zHXgoP0h1dadJe4DCWu25q4MhA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.138.85.121, 108.138.85.61, 108.138.85.41, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.138.85.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7695857280 (7.2G) [binary/octet-stream]\n",
            "Saving to: ‘kunoichi-dpo-v2-7b.Q8_0.gguf’\n",
            "\n",
            "kunoichi-dpo-v2-7b. 100%[===================>]   7.17G  58.9MB/s    in 2m 33s  \n",
            "\n",
            "2024-07-03 10:35:18 (48.1 MB/s) - ‘kunoichi-dpo-v2-7b.Q8_0.gguf’ saved [7695857280/7695857280]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "class FTDataset:\n",
        "    def __init__(self, sentences):\n",
        "        # Preprocess sentences to remove noise and irrelevant content\n",
        "        self.sentences = [self.preprocess_sentence(s) for s in sentences.split('.') if s.strip()]\n",
        "        self.sentence_embeddings = SentenceTransformer('all-mpnet-base-v2').encode(self.sentences)\n",
        "\n",
        "    def preprocess_sentence(self, sentence):\n",
        "        # Enhanced cleaning and normalization\n",
        "        sentence = sentence.strip()\n",
        "        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # Remove punctuation\n",
        "        sentence = unicodedata.normalize('NFKD', sentence)  # Normalize unicode\n",
        "        sentence = sentence.lower()  # Convert to lowercase (optional)\n",
        "        return sentence\n",
        "\n",
        "\n",
        "    def generate_text(self, prompt, k=3):  # Select top k sentences\n",
        "        prompt_embedding = SentenceTransformer('all-mpnet-base-v2').encode(prompt)\n",
        "        similarities = util.cos_sim(prompt_embedding, self.sentence_embeddings)\n",
        "        top_k_indices = similarities.argsort()[0][-k:]  # Get indices of top k similarities\n",
        "        return ' '.join([self.sentences[i] for i in top_k_indices])\n",
        "n_ctx = 2048  # Maximum number of tokens for the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMRREPG8HyE1",
        "outputId": "bfa58b35-6e48-41ff-f2bc-16aa6c2155e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path_barrie = '/content/text_data_barrie.txt'  # Replace with the actual path\n",
        "with open(file_path_barrie, \"r\", encoding='utf-8') as file:\n",
        "     text_data_barrie = file.read()\n",
        "ft_dataset_barrie = FTDataset(text_data_barrie)\n",
        "\n",
        "file_path_amit = '/content/text_data_amit.txt'  # Replace with the actual path\n",
        "with open(file_path_amit, \"r\", encoding='utf-8') as file:\n",
        "    text_data_amit = file.read()\n",
        "ft_dataset_amit = FTDataset(text_data_amit)"
      ],
      "metadata": {
        "id": "y_v9irZlHyBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o2yY9Zg1Okbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_barrie(prompt, model, dataset, max_tokens=n_ctx):\n",
        "    sentence = dataset.generate_text(prompt)\n",
        "    final_prompt = f\"{prompt} in the style of Barrie Painter ( Chief Sustainability Officer and Head of Global Marketing and Communications at  Motherson), and continue this sentence: '{sentence}'\"\n",
        "    # Parameters to control output quality\n",
        "\n",
        "\n",
        "     # Tokenize only the prompt to avoid encoding issues\n",
        "    prompt_tokens = model.tokenize(final_prompt.encode('utf-8'))\n",
        "\n",
        "    response = model.create_completion(prompt=final_prompt, max_tokens=n_ctx,       # Adjust this value\n",
        "        top_p=0.95,           # Experiment with this\n",
        "        temperature=0.3  )\n",
        "    generated_text = response['choices'][0]['text'].strip()\n",
        "\n",
        "    # Filter out questions and unnecessary output\n",
        "    generated_text = re.sub(r'\\?[^\\?]*$', '', generated_text)  # Remove trailing question marks\n",
        "    generated_text = re.sub(r'\\n+', '\\n', generated_text)  # Remove multiple newlines\n",
        "    generated_text = re.sub(r'\\n$', '', generated_text)  # Remove trailing newline\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "fRaFnWidHx9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_amit(prompt, model, dataset, max_tokens=n_ctx):\n",
        "    sentence = dataset.generate_text(prompt)\n",
        "    final_prompt = f\"{prompt} in the style of Amit Shah, who is not a part of Motherson group and will not write a post related to Motherson's and its entity, and continue this sentence: '{sentence}'\"\n",
        "    # Parameters to control output quality\n",
        "\n",
        "    # Ensure combined text is within max_tokens\n",
        "     # Tokenize only the prompt to avoid encoding issues\n",
        "    prompt_tokens = model.tokenize(final_prompt.encode('utf-8'))\n",
        "\n",
        "    response = model.create_completion(prompt=final_prompt, max_tokens=n_ctx,       # Adjust this value\n",
        "        top_p=0.94,           # Experiment with this\n",
        "        temperature=0.07  )\n",
        "    generated_text = response['choices'][0]['text'].strip()\n",
        "\n",
        "    # Filter out questions and unnecessary output\n",
        "    generated_text = re.sub(r'\\?[^\\?]*$', '', generated_text)  # Remove trailing question marks\n",
        "    generated_text = re.sub(r'\\n+', '\\n', generated_text)  # Remove multiple newlines\n",
        "    generated_text = re.sub(r'\\n$', '', generated_text)  # Remove trailing newline\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "FclrxSlQHx60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    st.set_page_config(page_title=\"Text Generation\", layout=\"wide\")\n",
        "    st.markdown(\"<h1 style='text-align: center; color: red;'>Persona.ai</h1>\", unsafe_allow_html=True)  # Centered title\n",
        "\n",
        "\n",
        "    # Download Model (moved outside of the loop)\n",
        "    # st.title(\"Persona.ai\")\n",
        "    # Download Model\n",
        "    model_url = \"https://huggingface.co/crestf411/daybreak-kunoichi-2dpo-7b-gguf/resolve/main/daybreak-kunoichi-2dpo-7b-q8_0.gguf\"\n",
        "    model_path = \"daybreak-kunoichi-2dpo-7b-q8_0.gguf\"\n",
        "    response = requests.get(model_url, stream=True)\n",
        "\n",
        "    llm= Llama(model_path, n_ctx=2048)\n",
        "\n",
        " # Input fields side-by-side\n",
        "    st.header(\"Enter your prompt:\")\n",
        "    user_input = st.text_input(\"Prompt:\", key=\"user_input\")\n",
        "\n",
        "    # Column width sliders\n",
        "    st.sidebar.header(\"Adjust Column Widths\")\n",
        "    barrie_width = st.sidebar.slider(\"Barrie Painter Width\", 1, 10, 4)  # Default 5/10\n",
        "    amit_width = st.sidebar.slider(\"Amit Shah Width\", 1, 10, 4)\n",
        "\n",
        "    # Output fields side-by-side\n",
        "    st.header(\"Generated Responses:\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    if user_input:\n",
        "        with col1:\n",
        "            st.subheader(\"Barrie Painter:\")\n",
        "            generated_text_barrie = generate_text_barrie(user_input, llm, ft_dataset_barrie,n_ctx)\n",
        "            st.write(generated_text_barrie)\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Amit Shah:\")\n",
        "            generated_text_amit = generate_text_amit(user_input, llm, ft_dataset_amit,n_ctx)\n",
        "            st.write(generated_text_amit)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1KwehzMHHx3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDVC03gPHx0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwcic4h5HxwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTOAkjg-Hxtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_95mHQgHxpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgQcK81NHxi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjdPCSKZHxf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_R7yZFEhHxVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}